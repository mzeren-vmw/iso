<pre class='metadata'>
Title: Container support for implicit lifetime types
Shortname: D1010
Revision: 0
Audience: LEWG, LWG
Status: D
Group: WG21
URL: http://wg21.link/D1010R0
!Source: <a href="https://github.com/mzeren-vmw/iso/blob/master/resize/d1010r0.bs">https://github.com/mzeren-vmw/iso/blob/master/resize/d1010r0.bs</a>
Editor: Mark Zeren, VMware, mzeren@vmware.com
Editor: Chris Kennelly, Google, ckennelly@google.com
Date: 2018-03-19
Markup Shorthands: markdown yes

Abstract: Extend <code>allocator_traits</code> and <code>vector</code> to allow
          efficient addition of elements of <em>implicit lifetime</em> type.

</pre>

Summary {#summary}
=======

[P0593R2] notes that "there is a family of types for which programmers assume they
do not need to explicitly create objects". These <em>implicit lifetime</em>
types are: <ul>

<li> Scalar types </li>

<li> Array types (with any element type) </li>

<li> Class types with a trivial destructor and a trivial constructor (of any
     kind) </li>

</ul

When working with contiguous containers of <em>implicit lifetime</em> types it
may be more efficient to initialize objects without explicit calls to
constructors. For example, the application may be reading elements from a file
or the network, or it may be stamping out a pattern of elements.

Allocator aware containers like `vector` must inform the allocator of
construction and destruction of objects, even when those operations are trivial.
This is accomplished with the following additions:

In [**allocator.requirements**] (Table 31) add:

<ul>

<li> `a.implicit_construct(c)` which informs the allocator of an implicit
     lifetime object that has been initialized by the application. This member
     function, if provided, does not participate in overload resolution unless
     <code>C</code> is an <em>implicit lifetime</em> type. By default it does
     nothing.

</ul>

In [**allocator.traits**] add:

<ul>

<li> `implicit_construct(Alloc& a, T* p)` - A member function which:
     <ul>

     <li> Calls `a.implicit_construct(p)` if it is well formed, otherwise ...
          </li>

     <li> Does nothing if T is an <em>implicit lifetime</em> type and
          `a.construct(p)` is <em>not</em> well formed, otherwise ... </li>

     <li> Does not participate in overload resolution.</li>

     </ul>
</li>
</ul>

With allocator support in place, we can enable the optimization for `vector` by
adding the following two member functions:

<ul>

<li> <code>T* uninitialized_data()</code> - Returns a pointer to storage that
     would back elements (<code>size()</code>, <code>capacity()</code>]. Note
     that this storage has indeterminate values. It may be initialized by
     casting to `void` and then to `char`, `usgigned char`, or `std::byte`. See
     ([**basic.life**]p6.4).

     Does not participate in overload resolution if
     `allocator_traits<Allocator>::construct_magcially(Element *)` is not well
     formed.

<li> <code>insert_from_capacity(size_type n)</code> - Appends <code>n</code>
     elements from capacity. The application must have initialized the storage
     backing these elements otherwise the behavior is undefined.

     Does not participate in overload resolution if
     `allocator_traits<Allocator>::construct_magcially(Element *)` is not well
     formed. </li>

</ul>


Motivating examples {#motivation}
==========

The extra overhead described in these examples is often small, however it can be
significant in performance critical execution paths.

Example: reading from the network
---------------------------------

The current `vector` inteface forces a copy when reading objects from the
network. `std::byte` keeps the example simple however the principle applies to
user defined <em>implicit lifetime</em> types:

<xmp>

using ByteVec = vector<byte>;

class Socket {
public:
    size_t Read(byte* buf, size_t size);
    ...
};

unsigned ReadSome(ByteVec& out, Socket& socket)
{
  byte buf[kBufferSize];
  size_t size = socket.Read(buf, kBufferSize);
  out.insert(out.end(), &buff[0], &buff[0] + size); // BAD: Copies.
  return size;
}
</xmp>


With the changes proposed in this paper the above example would be optimized as:

<xmp>
unsigned ReadSome(ByteVec& out, Socket& socket)
{
  out.reserve(out.size() + kBufferSize);
  size_t size = socket.Read(
      out.uninitialized_data(), data.capacity() - data.size());
  out.insert_from_capacity(out.end(), &buff[0], &buff[0] + size); // GOOD: No copies.
  return size;
}
</xmp>


Example: stamping a pattern
---------------------------

In this case, `vector`'s interface offers two options, neither optimial:

<ol>

<li> Call <strong><code>resize</code></strong> and write directly into the
     container. However, this <em>value initializes</em> elements, typically
     writing zeros: </li>

<xmp>
using IntVec = vector<int>;

void AppendPattern(IntVec& out, span<const int> pattern, unsigned count)
{
  auto start = out.size();
  auto size = static_cast<IntVec::size_type>(pattern.size());
  out.resize(start + size * count);       // BAD: Write a lot of zeros.
  //  ^^^^^^
  for (auto cur = out.begin() + start;
       cur < out.end(); cur += size) {
    memcpy(&*cur, pattern.data(), size)); // GOOD: No bookkeeping.
  }
}
</xmp>

<li> Call <strong><code>reserve</code></strong> and then <code>insert</code> in
     a loop. However, this incurs bookkeeping overhead in each insert: </li>

<xmp>
void AppendPattern(IntVec& out, span<const int> pattern, unsigned count)
{
  auto start = out.size();
  auto size = static_cast<IntVec::size_type>(pattern.size());
  out.reserve(out.size() + size * count);   // GOOD: No unnecessary writes.
  //  ^^^^^^^
  for (unsigned i = 0; i < count; ++i) {
    out.insert(out.end(), pattern.begin(),  // BAD: Bookkeeping in insert.
               pattern.end());
  }
}
</xmp>

</ol>

With the changes proposed in this paper the above examples would be optimized
as:

<ol>
<xmp>
void AppendPattern(IntVec& out, span<const int> pattern, unsigned count)
{
  auto start = out.size();
  auto size = static_cast<IntVec::size_type>(pattern.size());
  auto total = size * count;
  out.reserve(out.size() + total);                      // GOOD: No unnecessary writes.
  int* const end = out.uninitialized_data() + total;
  for (int* cur = out.uninitialized_data(); i < end; cur += size) {
    memcpy(&*cur, pattern.data(), size * sizeof(int))); // GOOD: No bookkeeping.
  }
  out.insert_from_capacity(total);
}
</xmp>
</ol>

Implementation Experience {#experience}
========================

Google <code>basic_string</code> {#google}
------

Google has hacked their internal <code>basic_string</code> implementation to
provide a related `resize_uninitialized` API and has measured performance
improvements (that are not public) that justify maintaining this extension.

Google's Abseil open source library provides hooks for other users that want to
independently apply the same hack. See:
<a href="https://github.com/abseil/abseil-cpp/blob/master/absl/strings/internal/resize_uninitialized.h">
https://github.com/abseil/abseil-cpp/blob/master/absl/strings/internal/resize_uninitialized.h</a>

Google's Protocol Buffers open source library takes advantage of Abseil's hooks
to improve performance. See:
<a href="https://github.com/google/protobuf/blob/master/src/google/protobuf/stubs/stl_util.h#L61">
https://github.com/google/protobuf/blob/master/src/google/protobuf/stubs/stl_util.h#L61</a>

Boost containers {#boost}
-----

Boost provides a related optimization for vector-like container:

* <a href="https://github.com/boostorg/container/commit/14f092ab00def8e692b81d57d0466a617a6f6130">
  Default initialization for vector-like containers</a> Ion Gaztañaga.

* <a href="https://github.com/boostorg/container/blob/develop/include/boost/container/vector.hpp">
  boost/container/vector.hpp</a>

<xmp>
   //! <b>Effects</b>: Constructs a vector that will use a copy of allocator a
   //!   and inserts n default initialized values.
   //!
   //! <b>Throws</b>: If allocator_type's allocation
   //!   throws or T's default initialization throws.
   //!
   //! <b>Complexity</b>: Linear to n.
   //!
   //! <b>Note</b>: Non-standard extension
   vector(size_type n, default_init_t);
   vector(size_type n, default_init_t, const allocator_type &a)
   ...
   void resize(size_type new_size, default_init_t);
   ...
</xmp>

These optimizations are also supported in Boost Container small_vector,
static_vector, deque, stable_vector, string.


VMware string builders {#vmware}
------

VMware has string builders that avoid <code>std::string</code> due, in part,
to <code>reserve</code>'s zero-writing behavior. This work was done without
knowledge of Google's <code>resize_uninitialized</code> extension.


Wording {#wording}
=======

TBD

Acknowledgements {#acknowledgements}
================

* <strong>Agustín Bergé</strong> provided guidence on object lifetime and
  allocator interactions.

References {#references}
==========

* XXX std-proposals discussion of basic_string::resize_uninitialized.
  https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/XIO4KbBTxl0

* XXX Glen Fernandes mentioned that he is working on a proposal to add default
  initialized make_unique/make_shared, etc. So not related to containers and
  allocators, but probably worth a reference when it becomes available.

* XXX Protocol Buffers
* XXX http://eel.is/c++draft/dcl.init#12
* XXX Abseil
* XXX Boost Containers
